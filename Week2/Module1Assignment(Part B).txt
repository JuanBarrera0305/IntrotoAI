Define in your own words the following terms: agent, agent function, agent program, rationality, autonomy, reflex agent, model-based agent, goal-based agent, utility-based agent, learning agent.
For each of the following activities, give a PEAS description of the task environment and characterize it in terms of the properties listed in the chapter:
Playing soccer.
Exploring the subsurface oceans of Titan.
Shopping for used AI books on the Internet. - Playing a tennis match.
Practicing tennis against a wall.
Performing a high jump.
Knitting a sweater.
Bidding on an item at an auction.
Consider a simple thermostat that turns on a furnace when the temperature is at least 3 degrees below the setting, and turns off a furnace when the temperature is at least 3 degrees above the setting. Is a thermostat an instance of a simple reflex agent, a model-based reflex agent, or a goal- based agent?


Answers:
Agent: Something that perceives its world with sensors and impacts the world with actuators.

Agent function: A mapping from percept histories (everything the agent has perceived up to this point) to actions. Actually, it determines what an agent should do depending on its history.

Agent program: An implementation of the agent function; the machine or algorithm that runs on a physical agent to figure out what it should do.

Rationality: Action that maximizes the expected performance measure, given the percept sequence and knowledge of the world.

Autonomy: The degree to which an agent can act on its own without intervention and relying on its internal knowledge to determine.

Reflex agent: A reflex agent that selects action depending on present percept, never considering history. Generally uses condition-action rules.

Model-based agent: Maintains an internal model of the environment in order to handle partially observable environments so that it is able to remember past states and make rational decisions.

Goal-based agent: Performs in an attempt to achieve specific objectives, considering future consequences of actions and planning sequences of actions to accomplish its objectives.

Utility-based agent: Uses a utility function in an attempt to reason about and compare feasible states, selecting actions maximizing total satisfaction or "happiness."

Learning agent: Continues to do better in the future by learning from experience and updating its knowledge or behavior.


Peas Description of Activities


Playing soccer

Performance measure: Goals that are scored, passes that are made, tackles, cooperation among the team members.
Environment: Soccer pitch, teammates, opponents, ball, public.
Actuators: Legs (kick, running), head (headball), arms (throw-in).
Sensors: Eyes, ears, proprioception, ball sensors.
Environment properties: Partially observable, stochastic, sequential, dynamic, continuous, multi-agent.

Exploring the subsurface oceans of Titan


Performance measure: Collected data, mission success, energy efficiency, safety.
Environment: Titan's subsurface ocean, rocks, ice, currents.
Actuators: Propellers, robotic arms, instruments.
Sensors: Sonar, cameras, chemical sensors, temperature sensors
Environment properties: Partially observable, stochastic, sequential, dynamic, continuous, single-agent or multi-agent if it involves more than one robot.

Shopping for used AI books on the Internet

Performance measure: Cheapest price, best shape, delivery speed, correct book.
Environment: Online marketplaces, seller listings.
Actuators: Mouse clicks, keyboard input.
Sensors: Web browser, website interface.
Environment properties: Partially observable, stochastic (prices/availability), sequential, dynamic (listings change), discrete, single-agent.
 

Playing a tennis match

Performance measure: Points won, unforced errors, accuracy.
Environment: Tennis court, ball, opponent.
Actuators: Racket, legs, arms, body.
Sensors: Eyes, proprioception, ears.
Environment properties: Partially observable, stochastic, sequential, dynamic, continuous, multi-agent.
 

Practicing tennis against a wall

Performance measure: Accuracy, consistency, speed, technique improvement.
Environment: Tennis court, wall, ball.
Actuators: Racket, legs, arms.
Sensors: Eyes, proprioception.
Environment properties: Fully observable, deterministic, sequential, dynamic, continuous, single-agent.
 

High jump performance

Performance measure: Height, technique.
Environment: High jump bar and runway.
Actuators: Legs, arms, torso.
Sensors: Eyes, proprioception.
Environment properties: Fully observable, deterministic, sequential, dynamic, continuous.
 

Knitting a sweater

Performance measure: Correctness of pattern, speed, quality, accuracy.
Environment: Pattern instructions, yarn, needles.
Actuators: Hands, fingers.
Sensors: Eyes, touch.
Environment properties: Fully observable, deterministic, sequential, dynamic, discrete.
Bidding on an item at an auction

Performance measure: Winning item at lowest price, not overbidding.
Environment: Auction platform, other bidders.
Actuators: Keyboard/mouse clicks.
Sensors: Bid updates, web interface.
Environment properties: Partially observable, uncertain, sequential, dynamic, discrete.

Thermostat Classification.


Because the thermostat described turns on when temperature ≤ setting − 3 and off when temperature ≥ setting + 3. Then we can say that It only reacts to a current temperature, but it does not maintain a model of past temperatures or plan for a goal beyond maintaining the temperature band. Based on this we can conclude that it is a simple reflex agent.